@inproceedings{amosOptNetDifferentiableOptimization2017,
  title = {{{OptNet}}: {{Differentiable Optimization}} as a {{Layer}} in {{Neural Networks}}},
  shorttitle = {{{OptNet}}},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Machine Learning}}},
  author = {Amos, Brandon and Kolter, J. Zico},
  year = {2017},
  month = jul,
  pages = {136--145},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v70/amos17a.html},
  urldate = {2022-10-13},
  abstract = {This paper presents OptNet, a network architecture that integrates optimization problems (here, specifically in the form of quadratic programs) as individual layers in larger end-to-end trainable deep networks. These layers encode constraints and complex dependencies between the hidden states that traditional convolutional and fully-connected layers often cannot capture. In this paper, we explore the foundations for such an architecture: we show how techniques from sensitivity analysis, bilevel optimization, and implicit differentiation can be used to exactly differentiate through these layers and with respect to layer parameters; we develop a highly efficient solver for these layers that exploits fast GPU-based batch solves within a primal-dual interior point method, and which provides backpropagation gradients with virtually no additional cost on top of the solve; and we highlight the application of these approaches in several problems. In one notable example, we show that the method is capable of learning to play mini-Sudoku (4x4) given just input and output games, with no a priori information about the rules of the game; this highlights the ability of our architecture to learn hard constraints better than other neural architectures.},
  langid = {english},
  keywords = {autodiff,done,inferopt,thesis},
  file = {/home/gdalle/snap/zotero-snap/common/Zotero/storage/EZRBDFJB/Amos and Kolter - 2017 - OptNet Differentiable Optimization as a Layer in .pdf;/home/gdalle/snap/zotero-snap/common/Zotero/storage/PQCHDRHL/Amos_Kolter_2017_OptNet.pdf}
}

@article{baydinAutomaticDifferentiationMachine2018,
  title = {Automatic {{Differentiation}} in {{Machine Learning}}: A {{Survey}}},
  shorttitle = {Automatic {{Differentiation}} in {{Machine Learning}}},
  author = {Baydin, Atilim Gunes and Pearlmutter, Barak A. and Radul, Alexey Andreyevich and Siskind, Jeffrey Mark},
  year = {2018},
  journal = {Journal of Machine Learning Research},
  volume = {18},
  number = {153},
  pages = {1--43},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v18/17-468.html},
  urldate = {2023-03-12},
  abstract = {Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in machine learning. Automatic differentiation (AD), also called algorithmic differentiation or simply {\^a}autodiff{\^a}, is a family of techniques similar to but more general than backpropagation for efficiently and accurately evaluating derivatives of numeric functions expressed as computer programs. AD is a small but established field with applications in areas including computational fluid dynamics, atmospheric sciences, and engineering design optimization. Until very recently, the fields of machine learning and AD have largely been unaware of each other and, in some cases, have independently discovered each other's results. Despite its relevance, general-purpose AD has been missing from the machine learning toolbox, a situation slowly changing with its ongoing adoption under the names {\^a}dynamic computational graphs{\^a} and {\^a}differentiable programming{\^a}. We survey the intersection of AD and machine learning, cover applications where AD has direct relevance, and address the main implementation techniques. By precisely defining the main differentiation techniques and their interrelationships, we aim to bring clarity to the usage of the terms {\^a}autodiff{\^a}, {\^a}automatic differentiation{\^a}, and {\^a}symbolic differentiation{\^a} as these are encountered more and more in machine learning settings.},
  keywords = {autodiff,done,inferopt,thesis,tracer},
  file = {/home/gdalle/snap/zotero-snap/common/Zotero/storage/MP87JETA/Baydin et al_2018_Automatic Differentiation in Machine Learning.pdf}
}

@inproceedings{blondelEfficientModularImplicit2022,
  title = {Efficient and {{Modular Implicit Differentiation}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Blondel, Mathieu and Berthet, Quentin and Cuturi, Marco and Frostig, Roy and Hoyer, Stephan and {Llinares-L{\'o}pez}, Felipe and Pedregosa, Fabian and Vert, Jean-Philippe},
  year = {2022},
  month = oct,
  url = {https://openreview.net/forum?id=Q-HOv_zn6G},
  urldate = {2023-03-12},
  abstract = {Automatic differentiation (autodiff) has revolutionized machine learning. It allows to express complex computations by composing elementary ones in creative ways and removes the burden of computing their derivatives by hand. More recently, differentiation of optimization problem solutions has attracted widespread attention with applications such as optimization layers, and in bi-level problems such as hyper-parameter optimization and meta-learning. However, so far, implicit differentiation remained difficult to use for practitioners, as it often required case-by-case tedious mathematical derivations and implementations. In this paper, we propose automatic implicit differentiation, an efficient and modular approach for implicit differentiation of optimization problems. In our approach, the user defines directly in Python a function \$F\$ capturing the optimality conditions of the problem to be differentiated. Once this is done, we leverage autodiff of \$F\$ and the implicit function theorem to automatically differentiate the optimization problem. Our approach thus combines the benefits of implicit differentiation and autodiff. It is efficient as it can be added on top of any state-of-the-art solver and modular as the optimality condition specification is decoupled from the implicit differentiation mechanism. We show that seemingly simple principles allow to recover many existing implicit differentiation methods and create new ones easily. We demonstrate the ease of formulating and solving bi-level optimization problems using our framework. We also showcase an application to the sensitivity analysis of molecular dynamics.},
  langid = {english},
  keywords = {autodiff,done,inferopt,thesis,tracer},
  file = {/home/gdalle/snap/zotero-snap/common/Zotero/storage/5MNWEQPU/Blondel et al. - 2022 - Efficient and Modular Implicit Differentiation.pdf}
}

@misc{blondelElementsDifferentiableProgramming2024,
  title = {The {{Elements}} of {{Differentiable Programming}}},
  author = {Blondel, Mathieu and Roulet, Vincent},
  year = {2024},
  month = jul,
  number = {arXiv:2403.14606},
  eprint = {2403.14606},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.14606},
  url = {http://arxiv.org/abs/2403.14606},
  urldate = {2024-08-06},
  abstract = {Artificial intelligence has recently experienced remarkable advances, fueled by large models, vast datasets, accelerated hardware, and, last but not least, the transformative power of differentiable programming. This new programming paradigm enables end-to-end differentiation of complex computer programs (including those with control flows and data structures), making gradient-based optimization of program parameters possible. As an emerging paradigm, differentiable programming builds upon several areas of computer science and applied mathematics, including automatic differentiation, graphical models, optimization and statistics. This book presents a comprehensive review of the fundamental concepts useful for differentiable programming. We adopt two main perspectives, that of optimization and that of probability, with clear analogies between the two. Differentiable programming is not merely the differentiation of programs, but also the thoughtful design of programs intended for differentiation. By making programs differentiable, we inherently introduce probability distributions over their execution, providing a means to quantify the uncertainty associated with program outputs.},
  archiveprefix = {arXiv},
  keywords = {autodiff,done},
  file = {/home/gdalle/snap/zotero-snap/common/Zotero/storage/6LFEKUZA/Blondel_Roulet_2024_The Elements of Differentiable Programming.pdf;/home/gdalle/snap/zotero-snap/common/Zotero/storage/7VQWVTKF/2403.html}
}

@article{gebremedhinWhatColorYour2005,
  title = {What {{Color Is Your Jacobian}}? {{Graph Coloring}} for {{Computing Derivatives}}},
  shorttitle = {What {{Color Is Your Jacobian}}?},
  author = {Gebremedhin, Assefaw Hadish and Manne, Fredrik and Pothen, Alex},
  year = {2005},
  month = jan,
  journal = {SIAM Review},
  volume = {47},
  number = {4},
  pages = {629--705},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1445},
  doi = {10/cmwds4},
  url = {https://epubs.siam.org/doi/abs/10.1137/S0036144504444711},
  urldate = {2022-02-03},
  abstract = {Graph coloring has been employed since the 1980s to efficiently compute sparse Jacobian and Hessian matrices using either finite differences or automatic differentiation. Several coloring problems occur in this context, depending on whether the matrix is a Jacobian or a Hessian, and on the specifics of the computational techniques employed. We consider eight variant vertex coloring problems here. This article begins with a gentle introduction to the problem of computing a sparse Jacobian, followed by an overview of the historical development of the research area. Then we present a unifying framework for the graph models of the variant matrix estimation problems. The framework is based upon the viewpoint that a partition of a matrix into structurally orthogonal groups of columns corresponds to distance-2 coloring an appropriate graph representation. The unified framework helps integrate earlier work and leads to fresh insights; enables the design of more efficient algorithms for many problems; leads to new algorithms for others; and eases the task of building graph models for new problems. We report computational results on two of the coloring problems to support our claims. Most of the methods for these problems treat a column or a row of a matrix as an atomic entity, and partition the columns or rows (or both). A brief review of methods that do not fit these criteria is provided. We also discuss results in discrete mathematics and theoretical computer science that intersect with the topics considered here.},
  keywords = {autodiff,semidone,tracer},
  file = {/home/gdalle/snap/zotero-snap/common/Zotero/storage/AGLB9RM8/Gebremedhin et al_2005_What Color Is Your Jacobian.pdf}
}

@book{griewankEvaluatingDerivativesPrinciples2008,
  title = {Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation},
  shorttitle = {Evaluating Derivatives},
  author = {Griewank, Andreas and Walther, Andrea},
  year = {2008},
  edition = {2nd ed},
  publisher = {{Society for Industrial and Applied Mathematics}},
  address = {Philadelphia, PA},
  abstract = {This title is a comprehensive treatment of algorithmic, or automatic, differentiation. The second edition covers recent developments in applications and theory, including an elegant NP completeness argument and an introduction to scarcity},
  isbn = {978-0-89871-659-7},
  lccn = {QA304 .G76 2008},
  keywords = {autodiff,inferopt,semidone,thesis,tracer},
  annotation = {OCLC: ocn227574816},
  file = {/home/gdalle/snap/zotero-snap/common/Zotero/storage/ZBNZIFGC/Griewank_Walther_2008_Evaluating Derivatives.pdf}
}

@misc{mandiDecisionFocusedLearningFoundations2023,
  title = {Decision-{{Focused Learning}}: {{Foundations}}, {{State}} of the {{Art}}, {{Benchmark}} and {{Future Opportunities}}},
  shorttitle = {Decision-{{Focused Learning}}},
  author = {Mandi, Jayanta and Kotary, James and Berden, Senne and Mulamba, Maxime and Bucarey, Victor and Guns, Tias and Fioretto, Ferdinando},
  year = {2023},
  month = jul,
  number = {arXiv:2307.13565},
  eprint = {2307.13565},
  primaryclass = {cs, math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.13565},
  url = {http://arxiv.org/abs/2307.13565},
  urldate = {2023-07-27},
  abstract = {Decision-focused learning (DFL) is an emerging paradigm in machine learning which trains a model to optimize decisions, integrating prediction and optimization in an end-to-end system. This paradigm holds the promise to revolutionize decision-making in many real-world applications which operate under uncertainty, where the estimation of unknown parameters within these decision models often becomes a substantial roadblock. This paper presents a comprehensive review of DFL. It provides an in-depth analysis of the various techniques devised to integrate machine learning and optimization models introduces a taxonomy of DFL methods distinguished by their unique characteristics, and conducts an extensive empirical evaluation of these methods proposing suitable benchmark dataset and tasks for DFL. Finally, the study provides valuable insights into current and potential future avenues in DFL research.},
  archiveprefix = {arXiv},
  keywords = {autodiff,corifer,done},
  file = {/home/gdalle/snap/zotero-snap/common/Zotero/storage/XSXDGJ6F/Mandi et al. - 2023 - Decision-Focused Learning Foundations, State of t.pdf;/home/gdalle/snap/zotero-snap/common/Zotero/storage/WLJLUUJG/2307.html}
}

@article{margossianReviewAutomaticDifferentiation2019,
  title = {A Review of Automatic Differentiation and Its Efficient Implementation},
  author = {Margossian, Charles C.},
  year = {2019},
  journal = {WIREs Data Mining and Knowledge Discovery},
  volume = {9},
  number = {4},
  pages = {e1305},
  issn = {1942-4795},
  doi = {10.1002/widm.1305},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/widm.1305},
  urldate = {2023-03-12},
  abstract = {Derivatives play a critical role in computational statistics, examples being Bayesian inference using Hamiltonian Monte Carlo sampling and the training of neural networks. Automatic differentiation (AD) is a powerful tool to automate the calculation of derivatives and is preferable to more traditional methods, especially when differentiating complex algorithms and mathematical functions. The implementation of AD, however, requires some care to insure efficiency. Modern differentiation packages deploy a broad range of computational techniques to improve applicability, run time, and memory management. Among these techniques are operation overloading, region-based memory, and expression templates. There also exist several mathematical techniques which can yield high performance gains when applied to complex algorithms. For example, semi-analytical derivatives can reduce by orders of magnitude the runtime required to numerically solve and differentiate an algebraic equation. Open and practical problems include the extension of current packages to provide more specialized routines, and finding optimal methods to perform higher-order differentiation. This article is categorized under: Algorithmic Development {$>$} Scalable Statistical Methods},
  langid = {english},
  keywords = {autodiff,done,inferopt,thesis,tracer},
  file = {/home/gdalle/snap/zotero-snap/common/Zotero/storage/G6C6EX8U/Margossian_2019_A review of automatic differentiation and its efficient implementation.pdf;/home/gdalle/snap/zotero-snap/common/Zotero/storage/2JWFI24S/widm.html}
}

@article{mohamedMonteCarloGradient2020,
  title = {Monte {{Carlo Gradient Estimation}} in {{Machine Learning}}},
  author = {Mohamed, Shakir and Rosca, Mihaela and Figurnov, Michael and Mnih, Andriy},
  year = {2020},
  journal = {Journal of Machine Learning Research},
  volume = {21},
  number = {132},
  pages = {1--62},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v21/19-346.html},
  urldate = {2022-10-21},
  abstract = {This paper is a broad and accessible survey of the methods we have at our disposal for Monte Carlo gradient estimation in machine learning and across the statistical sciences: the problem of computing the gradient of an expectation of a function with respect to parameters defining the distribution that is integrated; the problem of sensitivity analysis. In machine learning research, this gradient problem lies at the core of many learning problems, in supervised, unsupervised and reinforcement learning. We will generally seek to rewrite such gradients in a form that allows for Monte Carlo estimation, allowing them to be easily and efficiently used and analysed. We explore three strategies---the pathwise, score function, and measure-valued gradient estimators---exploring their historical development, derivation, and underlying assumptions. We describe their use in other fields, show how they are related and can be combined, and expand on their possible generalisations. Wherever Monte Carlo gradient estimators have been derived and deployed in the past, important advances have followed. A deeper and more widely-held understanding of this problem will lead to further advances, and it is these advances that we wish to support.},
  keywords = {autodiff,diffexp,done},
  file = {/home/gdalle/snap/zotero-snap/common/Zotero/storage/6KTY5IG4/Mohamed et al. - 2020 - Monte Carlo Gradient Estimation in Machine Learnin.pdf;/home/gdalle/snap/zotero-snap/common/Zotero/storage/IMI4JXES/mc_gradients.html}
}

@article{schulmanGradientEstimationUsing2015,
  title = {Gradient {{Estimation Using Stochastic Computation Graphs}}},
  author = {Schulman, John and Heess, Nicolas and Weber, Theophane and Abbeel, Pieter},
  year = {2015},
  month = jun,
  journal = {arXiv:1506.05254 [cs]},
  eprint = {1506.05254},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1506.05254},
  urldate = {2019-06-08},
  abstract = {In a variety of problems originating in supervised, unsupervised, and reinforcement learning, the loss function is defined by an expectation over a collection of random variables, which might be part of a probabilistic model or the external world. Estimating the gradient of this loss function, using samples, lies at the core of gradient-based learning algorithms for these problems. We introduce the formalism of stochastic computation graphs---directed acyclic graphs that include both deterministic functions and conditional probability distributions---and describe how to easily and automatically derive an unbiased estimator of the loss function's gradient. The resulting algorithm for computing the gradient estimator is a simple modification of the standard backpropagation algorithm. The generic scheme we propose unifies estimators derived in variety of prior work, along with variance-reduction techniques therein. It could assist researchers in developing intricate models involving a combination of stochastic and deterministic operations, enabling, for example, attention, memory, and control actions.},
  archiveprefix = {arXiv},
  keywords = {autodiff,done},
  file = {/home/gdalle/snap/zotero-snap/common/Zotero/storage/MCMS2BMX/Schulman et al_2015_Gradient Estimation Using Stochastic Computation Graphs.pdf;/home/gdalle/snap/zotero-snap/common/Zotero/storage/AULMDCMQ/1506.html}
}
